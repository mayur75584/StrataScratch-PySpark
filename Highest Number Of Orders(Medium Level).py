'''
Highest Number Of Orders


Last Updated: July 2025

Medium
ID 9909

11

Find the customer who has placed the highest number of orders. Output the id of the customer along with the corresponding number of orders.

Table
orders
More about this question
Hints
Expected Output
orders
Preview
id	cust_id	order_date	order_details	total_order_cost
1	3	2019-03-04	Coat	100
2	3	2019-03-01	Shoes	80
3	3	2019-03-07	Skirt	30
4	7	2019-02-01	Coat	25
5	7	2019-03-10	Shoes	80
6	15	2019-02-01	Boats	100
7	15	2019-01-11	Shirts	60
8	15	2019-03-11	Slipper	20
9	15	2019-03-01	Jeans	80
10	15	2019-03-09	Shirts	50
11	5	2019-02-01	Shoes	80
12	12	2019-01-11	Shirts	60
13	12	2019-03-11	Slipper	20
14	4	2019-02-01	Shoes	80
15	4	2019-01-11	Shirts	60
16	3	2019-04-19	Shirts	50
17	7	2019-04-19	Suit	150
18	15	2019-04-19	Skirt	30
19	15	2019-04-20	Dresses	200
20	12	2019-01-11	Coat	125
21	7	2019-04-01	Suit	50
22	7	2019-04-02	Skirt	30
23	7	2019-04-03	Dresses	50
24	7	2019-04-04	Coat	25
25	7	2019-04-19	Coat	125
26	3	2019-04-20	Gloves	20
27	3	2019-04-21	Tie	25
28	3	2019-04-22	Cap	15
29	3	2019-04-23	Jacket	120
30	1	2019-04-19	Jacket	150
31	1	2019-04-19	Shoes 	125
id:
bigint
cust_id:
bigint
order_date:
date
order_details:
string
total_order_cost:
bigint
'''

# Import your libraries
import pyspark
from pyspark.sql.functions import *
# Start writing code
df=customers
df_orders=orders

df1=df.join(df_orders,df.id==df_orders.cust_id,"left").drop(df_orders.id)
df2=df1.groupby("id").agg(count("order_details").alias("total_orders"))
df2=df2.orderBy(desc("total_orders")).limit(1)
# df2.show(truncate=False)
# df.show(truncate=False)
df2.toPandas()
# To validate your solution, convert your final pySpark df to a pandas df
# customers.toPandas()